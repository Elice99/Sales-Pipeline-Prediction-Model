{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "44989896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SALES PIPELINE PREDICTION - COMPLETE IMPLEMENTATION\n",
    "# ============================================================================\n",
    "# This code walks through every step with detailed comments\n",
    "# ============================================================================\n",
    "\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# For modeling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from category_encoders import CatBoostEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score, \n",
    "                             recall_score, f1_score, confusion_matrix, \n",
    "                             classification_report, roc_curve, auc, precision_recall_curve) \n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Set style for visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47331552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING AND EXPLORING DATA\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOADING AND EXPLORING DATA\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "696c173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = pyodbc.connect(\n",
    "    \"Driver={SQL Server};\"\n",
    "    \"Server=ELICE99\\\\SQLEXPRESS;\"\n",
    "    \"Database=CRM_Sales_Opportunity;\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b5620efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data loaded: 8300 records\n",
      "✓ Columns: 17\n"
     ]
    }
   ],
   "source": [
    "# Query to get data (excluding 'Prospecting' stage)\n",
    "query = '''\n",
    "SELECT p.*, \n",
    "    a.sector, a.year_established, a.account_tier, a.employees, a.office_location,\n",
    "    s.manager, s.regional_office\n",
    "FROM dbo.sales_pipeline p\n",
    "LEFT JOIN accounts a ON a.account = p.account\n",
    "LEFT JOIN sales_teams s ON p.sales_agent = s.sales_agent\n",
    "WHERE deal_stage NOT IN ('Prospecting')\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"✓ Data loaded: {len(df)} records\")\n",
    "print(f\"✓ Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e2114920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " EXPLORATORY DATA ANALYSIS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "74df1088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows:\n",
      "  opportunity_id      sales_agent         product  account deal_stage  \\\n",
      "0       1C1I7A6R      Moses Frase  GTX Plus Basic  Cancity        Won   \n",
      "1       Z063OYW0  Darcel Schlecht          GTXPro    Isdom        Won   \n",
      "2       EC4QE1BX  Darcel Schlecht      MG Special  Cancity        Won   \n",
      "3       MV1LWRNH      Moses Frase       GTX Basic  Codehow        Won   \n",
      "4       PE84CX4O        Zane Levy       GTX Basic   Hatfan        Won   \n",
      "\n",
      "  engage_date  close_date  close_value  is_active  deal_duration    sector  \\\n",
      "0  2016-10-20  2017-03-01         1054      False          132.0    Retail   \n",
      "1  2016-10-25  2017-03-11         4514      False          137.0   Medical   \n",
      "2  2016-10-25  2017-03-07           50      False          133.0    Retail   \n",
      "3  2016-10-25  2017-03-09          588      False          135.0  Software   \n",
      "4  2016-10-25  2017-03-02          517      False          128.0  Services   \n",
      "\n",
      "   year_established      account_tier  employees office_location  \\\n",
      "0            2001.0  Large_Enterprise     2448.0   United States   \n",
      "1            2002.0  Large_Enterprise     4540.0   United States   \n",
      "2            2001.0  Large_Enterprise     2448.0   United States   \n",
      "3            1998.0  Large_Enterprise     2641.0   United States   \n",
      "4            1982.0  Large_Enterprise     1299.0   United States   \n",
      "\n",
      "            manager regional_office  \n",
      "0  Dustin Brinkmann         Central  \n",
      "1     Melvin Marxen         Central  \n",
      "2     Melvin Marxen         Central  \n",
      "3  Dustin Brinkmann         Central  \n",
      "4     Summer Sewald            West  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "72d69a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Statistics:\n",
      "        close_value  deal_duration  year_established     employees\n",
      "count   8300.000000    6711.000000       7212.000000   7212.000000\n",
      "mean    1205.486024      47.985397       1995.454104   5737.717277\n",
      "std     2167.597195      41.057665          9.186596   6850.680603\n",
      "min        0.000000       1.000000       1979.000000      9.000000\n",
      "25%        0.000000       8.000000       1988.000000   1238.000000\n",
      "50%       49.000000      45.000000       1995.000000   3492.000000\n",
      "75%     1136.000000      85.000000       2002.000000   7523.000000\n",
      "max    30288.000000     138.000000       2017.000000  34288.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "64a1cdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(34288.0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['employees'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ffa7b1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     7212.000000\n",
       "mean      5737.717277\n",
       "std       6850.680603\n",
       "min          9.000000\n",
       "50%       3492.000000\n",
       "90%      16499.000000\n",
       "95%      17479.000000\n",
       "99%      34288.000000\n",
       "max      34288.000000\n",
       "Name: employees, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['employees'].describe(percentiles=[0.9,0.95,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2d1ff64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log transformation\n",
    "\n",
    "#since only few companies are this large, we capped the outliers\n",
    "df[\"employees_log\"]= np.log1p(df['employees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cdef4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#company size category\n",
    "\n",
    "bins = [0, 50, 250, 1000, 5000, 15000, np.inf]\n",
    "labels = ['micro', 'small', 'medium', 'large', 'enterprise', 'mega']\n",
    "df [\"company_size\"] = pd.cut(df['employees'], bins=bins, labels=labels).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "203d1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA CLEANING & LEAKAGE PREVENTION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA CLEANING & LEAKAGE PREVENTION\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ea47293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names (lowercase, underscores)\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d7d907d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Column names and values standardized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standardize string values\n",
    "string_cols = df.select_dtypes(include='object').columns\n",
    "for col in string_cols:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
    "\n",
    "print(\"✓ Column names and values standardized\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a643b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original deal_stage distribution:\n",
      "deal_stage\n",
      "won         4238\n",
      "lost        2473\n",
      "engaging    1589\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# CRITICAL: Keep only CLOSED deals (won or lost) for training\n",
    "print(\"\\nOriginal deal_stage distribution:\")\n",
    "print(df['deal_stage'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "64d3e4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering:\n",
      "Training data (won + lost): 6711 rows\n",
      "Active deals (to predict): 1589 rows\n"
     ]
    }
   ],
   "source": [
    "# Filter: Keep only won and lost deals for training\n",
    "df_training = df[df['deal_stage'].isin(['won', 'lost'])].copy()\n",
    "\n",
    "# Save active deals separately for later predictions\n",
    "df_active = df[df['deal_stage'] == 'engaging'].copy()\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"Training data (won + lost): {len(df_training)} rows\")\n",
    "print(f\"Active deals (to predict): {len(df_active)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e10704ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing leakage columns...\n",
      "Leakage columns removed: close_date, close_value, is_active, deal_duration, opportunity_id, employees, account_tier\n"
     ]
    }
   ],
   "source": [
    "# CRITICAL: DROP LEAKAGE COLUMNS\n",
    "print(\"\\nRemoving leakage columns...\")\n",
    "leakage_columns = ['close_date', 'close_value', 'is_active','deal_duration', 'opportunity_id','employees', 'account_tier']\n",
    "df_training = df_training.drop(columns=leakage_columns, errors='ignore')\n",
    "df_active = df_active.drop(columns=leakage_columns, errors='ignore')\n",
    "\n",
    "print(\"Leakage columns removed: close_date, close_value, is_active, deal_duration, opportunity_id, employees, account_tier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1e8d79ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATE TARGET VARIABLE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATE TARGET VARIABLE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4fded5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Distribution:\n",
      "target\n",
      "1    4238\n",
      "0    2473\n",
      "Name: count, dtype: int64\n",
      "\n",
      "won Rate: 63.15%\n"
     ]
    }
   ],
   "source": [
    "# Create binary target: 1 = Won, 0 = Lost\n",
    "df_training['target'] = (df_training['deal_stage'] == 'won').astype(int)\n",
    "\n",
    "print(\"\\nTarget Distribution:\")\n",
    "print(df_training['target'].value_counts())\n",
    "print(f\"\\nwon Rate: {df_training['target'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Drop deal_stage column (no longer needed)\n",
    "df_training = df_training.drop('deal_stage', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f11b25f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " TRAIN-TEST SPLIT\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" TRAIN-TEST SPLIT\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e8c266d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5368, 1343)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train, df_test = train_test_split(df_training, test_size=0.2, random_state=1)\n",
    "len(df_full_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a395f7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4026, 1343, 1342)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "len(df_train), len(df_test), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c9c9f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable (y) from the features (X) for the training and test sets\n",
    "y_train = df_train.target.values\n",
    "y_val = df_val.target.values\n",
    "y_test = df_test.target.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "61d8f2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    0.626428\n",
       "0    0.373572\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "849fc106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.626428216592151)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_rate = df_train.target.mean() \n",
    "win_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f55e36de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " FEATURE ENGINEERING\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" FEATURE ENGINEERING\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "48e87657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.1: Extracting Temporal Features...\n",
      "✓ Temporal features created: month, quarter, day_of_week, is_weekend, days_into_year\n"
     ]
    }
   ],
   "source": [
    "# -------- 5.1: TEMPORAL FEATURES FROM ENGAGE_DATE --------\n",
    "print(\"\\n5.1: Extracting Temporal Features...\")\n",
    "\n",
    "# Convert to datetime\n",
    "\n",
    "df_train['engage_date'] = pd.to_datetime(df_train['engage_date'])\n",
    "df_val['engage_date'] = pd.to_datetime(df_val['engage_date'])\n",
    "df_test['engage_date'] = pd.to_datetime(df_test['engage_date'])\n",
    "df_active['engage_date'] = pd.to_datetime(df_active['engage_date'])\n",
    "\n",
    "\n",
    "# Extract temporal features\n",
    "df_train['month_engaged'] = df_train['engage_date'].dt.month\n",
    "df_train['quarter_engaged'] = df_train['engage_date'].dt.quarter\n",
    "df_train['day_of_week_engaged'] = df_train['engage_date'].dt.dayofweek\n",
    "df_train['is_weekend'] = (df_train['day_of_week_engaged'].isin([5, 6])).astype(int)\n",
    "df_train['days_into_year'] = df_train['engage_date'].dt.dayofyear\n",
    "\n",
    "# Extract temporal features\n",
    "df_val['month_engaged'] = df_val['engage_date'].dt.month\n",
    "df_val['quarter_engaged'] = df_val['engage_date'].dt.quarter\n",
    "df_val['day_of_week_engaged'] = df_val['engage_date'].dt.dayofweek\n",
    "df_val['is_weekend'] = (df_val['day_of_week_engaged'].isin([5, 6])).astype(int)\n",
    "df_val['days_into_year'] = df_val['engage_date'].dt.dayofyear\n",
    "\n",
    "# Extract temporal features\n",
    "df_test['month_engaged'] = df_test['engage_date'].dt.month\n",
    "df_test['quarter_engaged'] = df_test['engage_date'].dt.quarter\n",
    "df_test['day_of_week_engaged'] = df_test['engage_date'].dt.dayofweek\n",
    "df_test['is_weekend'] = (df_test['day_of_week_engaged'].isin([5, 6])).astype(int)\n",
    "df_test['days_into_year'] = df_test['engage_date'].dt.dayofyear\n",
    "\n",
    "# Apply same to active deals\n",
    "df_active['month_engaged'] = df_active['engage_date'].dt.month\n",
    "df_active['quarter_engaged'] = df_active['engage_date'].dt.quarter\n",
    "df_active['day_of_week_engaged'] = df_active['engage_date'].dt.dayofweek\n",
    "df_active['is_weekend'] = (df_active['day_of_week_engaged'].isin([5, 6])).astype(int)\n",
    "df_active['days_into_year'] = df_active['engage_date'].dt.dayofyear\n",
    "\n",
    "print(\"✓ Temporal features created: month, quarter, day_of_week, is_weekend, days_into_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c49e1cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.2: Calculating Deal Duration...\n",
      "  Reference date: 2017-12-31\n"
     ]
    }
   ],
   "source": [
    "# -------- 5.2: DEAL DURATION --------\n",
    "print(\"\\n5.2: Calculating Deal Duration...\")\n",
    "\n",
    "# Convert to datetime\n",
    "df['engage_date'] = pd.to_datetime(df['engage_date'])\n",
    "df['close_date'] = pd.to_datetime(df['close_date'], errors='coerce')\n",
    "\n",
    "# Get reference date as the max date in dataset\n",
    "ref_date = df[['engage_date', 'close_date']].max().max()\n",
    "print(f\"  Reference date: {ref_date.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7e09166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Deal age calculated\n",
      "  Average: 48 days\n",
      "  Min-Max: 1 - 137 days\n"
     ]
    }
   ],
   "source": [
    "# Calculate deal duration\n",
    "df['closed_duration'] = (df['close_date'] - df['engage_date']).dt.days\n",
    "df['active_duration'] = (ref_date - df['engage_date']).dt.days\n",
    "df['deal_age'] = df['closed_duration'].fillna(df['active_duration'])\n",
    "\n",
    "# Apply to training and active data\n",
    "\n",
    "df_train['deal_age'] = df.loc[df_train.index, 'deal_age'].values\n",
    "df_val['deal_age'] = df.loc[df_val.index, 'deal_age'].values\n",
    "df_test['deal_age'] = df.loc[df_test.index, 'deal_age'].values\n",
    "df_active['deal_age'] = df.loc[df_active.index, 'deal_age'].values\n",
    "\n",
    "print(f\"✓ Deal age calculated\")\n",
    "print(f\"  Average: {df_train['deal_age'].mean():.0f} days\")\n",
    "print(f\"  Min-Max: {df_train['deal_age'].min():.0f} - {df_train['deal_age'].max():.0f} days\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "32e53cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Interaction Features...\n"
     ]
    }
   ],
   "source": [
    "# --------  INTERACTION FEATURES --------\n",
    "print(\"\\nCreating Interaction Features...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8bae7520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_agent</th>\n",
       "      <th>agent_win_rate</th>\n",
       "      <th>agent_total_deals</th>\n",
       "      <th>agent_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>wilburn_farren</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hayden_neloms</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>86</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>james_ascencio</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>126</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>moses_frase</td>\n",
       "      <td>0.680328</td>\n",
       "      <td>122</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cecily_lampkin</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>100</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sales_agent  agent_win_rate  agent_total_deals  agent_win\n",
       "28  wilburn_farren        0.800000                 40         32\n",
       "11   hayden_neloms        0.697674                 86         60\n",
       "12  james_ascencio        0.690476                126         87\n",
       "20     moses_frase        0.680328                122         83\n",
       "3   cecily_lampkin        0.680000                100         68"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sales Agent Performance\n",
    "agent_stats = df_train.groupby('sales_agent').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "agent_stats.columns = ['sales_agent', 'agent_win_rate', 'agent_total_deals', 'agent_win']\n",
    "\n",
    "df_train = df_train.merge(agent_stats, on='sales_agent', how='left')\n",
    "df_val = df_val.merge(agent_stats, on='sales_agent', how='left')\n",
    "df_test = df_test.merge(agent_stats, on='sales_agent', how='left')\n",
    "df_active = df_active.merge(agent_stats, on='sales_agent', how='left')\n",
    "\n",
    "agent_stats.sort_values(by='agent_win_rate', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5c3cf5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>account_win_rate</th>\n",
       "      <th>account_deal_count</th>\n",
       "      <th>account_total_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>newex</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>zencorporation</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>rangreen</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>zoomit</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>inity</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           account  account_win_rate  account_deal_count  account_total_win\n",
       "50           newex          0.781250                  32                 25\n",
       "81  zencorporation          0.760000                  25                 19\n",
       "56        rangreen          0.757143                  70                 53\n",
       "82          zoomit          0.750000                  28                 21\n",
       "37           inity          0.736842                  57                 42"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# account Performance\n",
    "account_stats = df_train.groupby('account').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "account_stats.columns = ['account', 'account_win_rate', 'account_deal_count', 'account_total_win']\n",
    "\n",
    "df_train = df_train.merge(account_stats, on='account', how='left')\n",
    "df_val = df_val.merge(account_stats, on='account', how='left')\n",
    "df_test = df_test.merge(account_stats, on='account', how='left')\n",
    "df_active = df_active.merge(account_stats, on='account', how='left')\n",
    "\n",
    "account_stats.sort_values(by='account_win_rate', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5990c432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sector</th>\n",
       "      <th>sector_win_rate</th>\n",
       "      <th>sector_deal_count</th>\n",
       "      <th>sector_total_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>services</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>206</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>employment</td>\n",
       "      <td>0.647399</td>\n",
       "      <td>173</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marketing</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>350</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>technolgy</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>632</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>software</td>\n",
       "      <td>0.632794</td>\n",
       "      <td>433</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sector  sector_win_rate  sector_deal_count  sector_total_win\n",
       "6    services         0.665049                206               137\n",
       "0  employment         0.647399                173               112\n",
       "3   marketing         0.634286                350               222\n",
       "8   technolgy         0.632911                632               400\n",
       "7    software         0.632794                433               274"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sector Performance\n",
    "sector_stats = df_train.groupby('sector').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "sector_stats.columns = ['sector', 'sector_win_rate', 'sector_deal_count', 'sector_total_win']\n",
    "\n",
    "df_train = df_train.merge(sector_stats, on='sector', how='left')\n",
    "df_val = df_val.merge(sector_stats, on='sector', how='left')\n",
    "df_test = df_test.merge(sector_stats, on='sector', how='left')\n",
    "df_active = df_active.merge(sector_stats, on='sector', how='left')\n",
    "\n",
    "sector_stats.sort_values(by='sector_win_rate', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "21b89463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>office_location</th>\n",
       "      <th>office_win_rate</th>\n",
       "      <th>office_deal_count</th>\n",
       "      <th>office_total_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>germany</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>china</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>panama</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brazil</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>belgium</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>64</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   office_location  office_win_rate  office_deal_count  office_total_win\n",
       "3          germany         0.781250                 32                25\n",
       "2            china         0.760000                 25                19\n",
       "10          panama         0.757143                 70                53\n",
       "1           brazil         0.678571                 28                19\n",
       "0          belgium         0.671875                 64                43"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Office Location Performance\n",
    "office_stats = df_train.groupby('office_location').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "office_stats.columns = ['office_location', 'office_win_rate', 'office_deal_count', 'office_total_win']\n",
    "\n",
    "df_train = df_train.merge(office_stats, on='office_location', how='left')\n",
    "df_val = df_val.merge(office_stats, on='office_location', how='left')\n",
    "df_test = df_test.merge(office_stats, on='office_location', how='left')\n",
    "df_active = df_active.merge(office_stats, on='office_location', how='left')\n",
    "\n",
    "office_stats.sort_values(by='office_win_rate', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dd4d8f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regional_office</th>\n",
       "      <th>region_win_rate</th>\n",
       "      <th>region_deal_count</th>\n",
       "      <th>region_total_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>west</td>\n",
       "      <td>0.635549</td>\n",
       "      <td>1339</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>central</td>\n",
       "      <td>0.631074</td>\n",
       "      <td>1564</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>east</td>\n",
       "      <td>0.609083</td>\n",
       "      <td>1123</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  regional_office  region_win_rate  region_deal_count  region_total_win\n",
       "2            west         0.635549               1339               851\n",
       "0         central         0.631074               1564               987\n",
       "1            east         0.609083               1123               684"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regional Office Performance\n",
    "region_stats = df_train.groupby('regional_office').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "region_stats.columns = ['regional_office', 'region_win_rate', 'region_deal_count', 'region_total_win']\n",
    "\n",
    "df_train = df_train.merge(region_stats, on='regional_office', how='left')\n",
    "df_val = df_val.merge(region_stats, on='regional_office', how='left')\n",
    "df_test = df_test.merge(region_stats, on='regional_office', how='left')\n",
    "df_active = df_active.merge(region_stats, on='regional_office', how='left')\n",
    "\n",
    "region_stats.sort_values(by='region_win_rate', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "49335e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_size_win_rate</th>\n",
       "      <th>company_size_deal_count</th>\n",
       "      <th>company_size_total_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>micro</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>104</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enterprise</td>\n",
       "      <td>0.634167</td>\n",
       "      <td>1159</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large</td>\n",
       "      <td>0.627574</td>\n",
       "      <td>1748</td>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medium</td>\n",
       "      <td>0.619444</td>\n",
       "      <td>360</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>small</td>\n",
       "      <td>0.617778</td>\n",
       "      <td>225</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_size  company_size_win_rate  company_size_deal_count  \\\n",
       "4        micro               0.692308                      104   \n",
       "0   enterprise               0.634167                     1159   \n",
       "1        large               0.627574                     1748   \n",
       "2       medium               0.619444                      360   \n",
       "5        small               0.617778                      225   \n",
       "\n",
       "   company_size_total_win  \n",
       "4                      72  \n",
       "0                     735  \n",
       "1                    1097  \n",
       "2                     223  \n",
       "5                     139  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# company_size Performance\n",
    "company_size_stats = df_train.groupby('company_size').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "company_size_stats.columns = ['company_size', 'company_size_win_rate', 'company_size_deal_count', 'company_size_total_win']\n",
    "\n",
    "df_train = df_train.merge(company_size_stats, on='company_size', how='left')\n",
    "df_val = df_val.merge(company_size_stats, on='company_size', how='left')\n",
    "df_test = df_test.merge(company_size_stats, on='company_size', how='left')\n",
    "df_active = df_active.merge(company_size_stats, on='company_size', how='left')\n",
    "\n",
    "company_size_stats.sort_values(by='company_size_win_rate', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d12226f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>product_win_rate</th>\n",
       "      <th>product_deal_count</th>\n",
       "      <th>product_total_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mg_special</td>\n",
       "      <td>0.652703</td>\n",
       "      <td>740</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gtx_plus_pro</td>\n",
       "      <td>0.650549</td>\n",
       "      <td>455</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gtx_basic</td>\n",
       "      <td>0.640279</td>\n",
       "      <td>859</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gtx_plus_basic</td>\n",
       "      <td>0.626427</td>\n",
       "      <td>613</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gtxpro</td>\n",
       "      <td>0.609618</td>\n",
       "      <td>707</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mg_advanced</td>\n",
       "      <td>0.582812</td>\n",
       "      <td>640</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gtk_500</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product  product_win_rate  product_deal_count  product_total_win\n",
       "6      mg_special          0.652703                 740                483\n",
       "3    gtx_plus_pro          0.650549                 455                296\n",
       "1       gtx_basic          0.640279                 859                550\n",
       "2  gtx_plus_basic          0.626427                 613                384\n",
       "4          gtxpro          0.609618                 707                431\n",
       "5     mg_advanced          0.582812                 640                373\n",
       "0         gtk_500          0.416667                  12                  5"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Product Performance\n",
    "product_stats = df_train.groupby('product').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "product_stats.columns = ['product', 'product_win_rate', 'product_deal_count', 'product_total_win']\n",
    "\n",
    "df_train = df_train.merge(product_stats, on='product', how='left')\n",
    "df_val = df_val.merge(product_stats, on='product', how='left')\n",
    "df_test = df_test.merge(product_stats, on='product', how='left')\n",
    "df_active = df_active.merge(product_stats, on='product', how='left')\n",
    "\n",
    "product_stats.sort_values(by='product_win_rate', ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1f4e4b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_agent</th>\n",
       "      <th>agent_avg_days_to_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>moses_frase</td>\n",
       "      <td>61.393443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>niesha_huffines</td>\n",
       "      <td>56.825243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lajuana_vencill</td>\n",
       "      <td>56.080882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anna_snelling</td>\n",
       "      <td>53.254902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>violet_mclelland</td>\n",
       "      <td>52.156522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sales_agent  agent_avg_days_to_close\n",
       "20       moses_frase                61.393443\n",
       "21   niesha_huffines                56.825243\n",
       "16   lajuana_vencill                56.080882\n",
       "0      anna_snelling                53.254902\n",
       "27  violet_mclelland                52.156522"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate Baseline Speed per Agent\n",
    "agent_speed = df_train.groupby('sales_agent')['deal_age'].mean().reset_index()\n",
    "agent_speed.columns = ['sales_agent', 'agent_avg_days_to_close']\n",
    "\n",
    "df_train = df_train.merge(agent_speed, on='sales_agent', how='left')\n",
    "df_val = df_val.merge(agent_speed, on='sales_agent', how='left')\n",
    "df_test = df_test.merge(agent_speed, on='sales_agent', how='left')\n",
    "df_active = df_active.merge(agent_speed, on='sales_agent', how='left')\n",
    "\n",
    "agent_speed.sort_values(by='agent_avg_days_to_close', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d77bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global average speed for agents not seen in training\n",
    "global_avg_speed = agent_speed['agent_avg_days_to_close'].mean()\n",
    "\n",
    "# Fill NaN for new agents with the global average speed\n",
    "df_train['agent_avg_days_to_close'] = df_train['agent_avg_days_to_close'].fillna(global_avg_speed)\n",
    "df_val['agent_avg_days_to_close'] = df_val['agent_avg_days_to_close'].fillna(global_avg_speed)\n",
    "df_test['agent_avg_days_to_close'] = df_test['agent_avg_days_to_close'].fillna(global_avg_speed)\n",
    "df_active['agent_avg_days_to_close'] = df_active['agent_avg_days_to_close'].fillna(global_avg_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e65e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Aggregation features created:\n",
      "  - agent_win_rate, agent_total_deals\n",
      "  - product_lost_rate, product_deal_count\n",
      "  - sector_win_rate, sector_deal_count\n",
      "  - company_size_win_rate, company_size_deal_count\n",
      "  - region_win_rate, region_deal_count\n"
     ]
    }
   ],
   "source": [
    "print(\"✓ Aggregation features created:\")\n",
    "print(f\"  - agent_win_rate, agent_total_deals\")\n",
    "print(f\"  - product_lost_rate, product_deal_count\")\n",
    "print(f\"  - sector_win_rate, sector_deal_count\")\n",
    "print(f\"  - company_size_win_rate, company_size_deal_count\")\n",
    "print(f\"  - region_win_rate, region_deal_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e37d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created advanced interaction features\n"
     ]
    }
   ],
   "source": [
    "# Agent-Product performance synergy\n",
    "df_train['agent_product_synergy'] = df_train['agent_win_rate'] * df_train['product_win_rate']\n",
    "df_val['agent_product_synergy'] = df_val['agent_win_rate'] * df_val['product_win_rate']\n",
    "df_test['agent_product_synergy'] = df_test['agent_win_rate'] * df_test['product_win_rate']\n",
    "df_active['agent_product_synergy'] = df_active['agent_win_rate'] * df_active['product_win_rate']\n",
    "\n",
    "# Agent efficiency metrics\n",
    "df_train['agent_win_efficiency'] = (1 - df_train['agent_win_rate']) * df_train['agent_total_deals']\n",
    "df_val['agent_win_efficiency'] = (1 - df_val['agent_win_rate']) * df_val['agent_total_deals']\n",
    "df_test['agent_win_efficiency'] = (1 - df_test['agent_win_rate']) * df_test['agent_total_deals']\n",
    "df_active['agent_win_efficiency'] = (1 - df_active['agent_win_rate']) * df_active['agent_total_deals']\n",
    "\n",
    "# Performance relative to sector\n",
    "df_train['agent_vs_sector'] = df_train['agent_win_rate'] - df_train['sector_win_rate']\n",
    "df_val['agent_vs_sector'] = df_val['agent_win_rate'] - df_val['sector_win_rate']\n",
    "df_test['agent_vs_sector'] = df_test['agent_win_rate'] - df_test['sector_win_rate']\n",
    "df_active['agent_vs_sector'] = df_active['agent_win_rate'] - df_active['sector_win_rate']\n",
    "\n",
    "# Deal complexity score\n",
    "df_train['deal_complexity'] = (df_train['employees_log'] * df_train['deal_age'] / (df_train['agent_total_deals'] + 1))\n",
    "df_val['deal_complexity'] = (df_val['employees_log'] * df_val['deal_age'] / (df_val['agent_total_deals'] + 1))\n",
    "df_test['deal_complexity'] = (df_test['employees_log'] * df_test['deal_age'] / (df_test['agent_total_deals'] + 1))\n",
    "df_active['deal_complexity'] = (df_active['employees_log'] * df_active['deal_age'] / (df_active['agent_total_deals'] + 1))\n",
    "\n",
    "# Office load vs performance\n",
    "df_train['office_load'] = df_train['office_deal_count'] / (df_train['office_total_win'] + 1)\n",
    "df_val['office_load'] = df_val['office_deal_count'] / (df_val['office_total_win'] + 1)\n",
    "df_test['office_load'] = df_test['office_deal_count'] / (df_test['office_total_win'] + 1)\n",
    "df_active['office_load'] = df_active['office_deal_count'] / (df_active['office_total_win'] + 1)\n",
    "\n",
    "# Product-sector fit\n",
    "df_train['product_sector_fit'] = df_train['product_win_rate'] * df_train['sector_win_rate']\n",
    "df_val['product_sector_fit'] = df_val['product_win_rate'] * df_val['sector_win_rate']\n",
    "df_test['product_sector_fit'] = df_test['product_win_rate'] * df_test['sector_win_rate']\n",
    "df_active['product_sector_fit'] = df_active['product_win_rate'] * df_active['sector_win_rate']\n",
    "\n",
    "# Regional performance relative to company size\n",
    "df_train['region_size_match'] = df_train['region_win_rate'] * df_train['company_size_win_rate']\n",
    "df_val['region_size_match'] = df_val['region_win_rate'] * df_val['company_size_win_rate']\n",
    "df_test['region_size_match'] = df_test['region_win_rate'] * df_test['company_size_win_rate']\n",
    "df_active['region_size_match'] = df_active['region_win_rate'] * df_active['company_size_win_rate']\n",
    "\n",
    "# Temporal risk factors\n",
    "df_train['quarter_risk'] = df_train['quarter_engaged'].map({1: 0.8, 2: 0.9, 3: 1.0, 4: 1.2})\n",
    "df_val['quarter_risk'] = df_val['quarter_engaged'].map({1: 0.8, 2: 0.9, 3: 1.0, 4: 1.2})\n",
    "df_test['quarter_risk'] = df_test['quarter_engaged'].map({1: 0.8, 2: 0.9, 3: 1.0, 4: 1.2})\n",
    "df_active['quarter_risk'] = df_active['quarter_engaged'].map({1: 0.8, 2: 0.9, 3: 1.0, 4: 1.2})\n",
    "\n",
    "df_train['is_quarter_end'] = df_train['month_engaged'].isin([3, 6, 9, 12]).astype(int)\n",
    "df_val['is_quarter_end'] = df_val['month_engaged'].isin([3, 6, 9, 12]).astype(int)\n",
    "df_test['is_quarter_end'] = df_test['month_engaged'].isin([3, 6, 9, 12]).astype(int)\n",
    "df_active['is_quarter_end'] = df_active['month_engaged'].isin([3, 6, 9, 12]).astype(int)\n",
    "\n",
    "epsilon = 1e-6\n",
    "df_train['sales_velocity_ratio'] = df_train['deal_age'] / (df_train['agent_avg_days_to_close'] + epsilon)\n",
    "df_val['sales_velocity_ratio'] = df_val['deal_age'] / (df_val['agent_avg_days_to_close'] + epsilon)\n",
    "df_test['sales_velocity_ratio'] = df_test['deal_age'] / (df_test['agent_avg_days_to_close'] + epsilon)\n",
    "df_active['sales_velocity_ratio'] = df_active['deal_age'] / (df_active['agent_avg_days_to_close'] + epsilon)\n",
    "\n",
    "# Agent Win Rate / Sales Velocity Ratio\n",
    "df_train['pace_weighted_agent_score'] = df_train['agent_win_rate'] / (df_train['sales_velocity_ratio'] + epsilon)\n",
    "df_val['pace_weighted_agent_score'] = df_val['agent_win_rate'] / (df_val['sales_velocity_ratio'] + epsilon)\n",
    "df_test['pace_weighted_agent_score'] = df_test['agent_win_rate'] / (df_test['sales_velocity_ratio'] + epsilon)\n",
    "df_active['pace_weighted_agent_score'] = df_active['agent_win_rate'] / (df_active['sales_velocity_ratio'] + epsilon)\n",
    "\n",
    "# Sales Velocity Ratio * Employees Log\n",
    "df_train['velocity_complexity_index'] = df_train['sales_velocity_ratio'] * df_train['employees_log']\n",
    "df_val['velocity_complexity_index'] = df_val['sales_velocity_ratio'] * df_val['employees_log']\n",
    "df_test['velocity_complexity_index'] = df_test['sales_velocity_ratio'] * df_test['employees_log']\n",
    "df_active['velocity_complexity_index'] = df_active['sales_velocity_ratio'] * df_active['employees_log']\n",
    "\n",
    "print(\"✓ Created advanced interaction features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38cb559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['engage_date'])\n",
    "df_val = df_val.drop(columns=['engage_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5790470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the target variable from the feature DataFrames\n",
    "del df_train['target']\n",
    "del df_val['target']\n",
    "del df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final list of features for the tree-based models (XGBoost/LightGBM)\n",
    "numerical = [\n",
    "    'year_established', 'employees_log', 'deal_age',\n",
    "    # Manual Target Encoded Features (Win Rates)\n",
    "    'agent_win_rate', 'account_win_rate', 'sector_win_rate', 'office_win_rate', 'region_win_rate', 'company_size_win_rate',\n",
    "    'product_win_rate', 'agent_avg_days_to_close', \n",
    "    \n",
    "    'agent_total_deals', 'agent_win', 'account_deal_count', 'account_total_win', 'sector_deal_count', 'sector_total_win',\n",
    "    'office_deal_count', 'office_total_win', 'region_deal_count', 'region_total_win', 'company_size_deal_count', 'company_size_total_win',\n",
    "    'product_deal_count', 'product_total_win', \n",
    "    \n",
    "    # Interaction/Complexity Features\n",
    "    'agent_product_synergy', 'agent_win_efficiency', 'agent_vs_sector', 'deal_complexity', 'office_load', 'product_sector_fit',\n",
    "    'region_size_match', 'quarter_risk', 'is_quarter_end', \n",
    "    'sales_velocity_ratio', 'pace_weighted_agent_score', 'velocity_complexity_index', \n",
    "    \n",
    "    # Temporal Features\n",
    "    'month_engaged', 'quarter_engaged', 'day_of_week_engaged',\n",
    "    'is_weekend', 'days_into_year'\n",
    "]\n",
    "\n",
    "numerical_eng = [\n",
    "    'year_established', 'employees_log', 'deal_age',\n",
    "    # Manual Target Encoded Features (Win Rates)\n",
    "    'agent_win_rate', 'account_win_rate', 'sector_win_rate', 'office_win_rate', 'region_win_rate', 'company_size_win_rate',\n",
    "    'product_win_rate', 'agent_avg_days_to_close',\n",
    "    \n",
    "    # Interaction/Complexity Features\n",
    "    'agent_product_synergy', 'agent_win_efficiency', 'agent_vs_sector', 'deal_complexity', 'office_load', 'product_sector_fit',\n",
    "    'region_size_match', 'quarter_risk', 'is_quarter_end', # Comma added here\n",
    "    'sales_velocity_ratio', 'pace_weighted_agent_score', 'velocity_complexity_index', # Commas added here\n",
    "    \n",
    "    # Temporal Features\n",
    "    'month_engaged', 'quarter_engaged', 'day_of_week_engaged', 'is_weekend', 'days_into_year'\n",
    "]\n",
    "\n",
    "categorical = [\n",
    "       'sales_agent', \n",
    "       'product', \n",
    "       'account', \n",
    "       #'engage_date', \n",
    "        'sector',\n",
    "        'office_location', \n",
    "        'manager', \n",
    "        'regional_office',\n",
    "        'company_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70613bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Target Encoding for Categorical Features...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nApplying Target Encoding for Categorical Features...\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68586a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Features encoded and scaled for logistic regression\n"
     ]
    }
   ],
   "source": [
    "preprocess_lr = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'), categorical),\n",
    "        ('scaler', StandardScaler(), \n",
    "         numerical)\n",
    "        ], \n",
    "    remainder='drop')\n",
    "\n",
    "print(\"✓ Features encoded and scaled for logistic regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b0135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Features encoded for boosting\n"
     ]
    }
   ],
   "source": [
    "preprocess_gb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cb', CatBoostEncoder(cols=categorical), categorical)], remainder='passthrough')\n",
    "\n",
    "print(\"✓ Features encoded for boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd975781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " FEATURE IMPORTANCE: CORRELATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" FEATURE IMPORTANCE: CORRELATION\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e9d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING OPTIMIZED MODELS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING OPTIMIZED MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "models_optimized = {}\n",
    "results_optimized = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589a7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Optimized XGBoost...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ XGBoost trained\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\nTraining Optimized XGBoost...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Calculate scale_pos_weight\n",
    "n_pos = sum(y_train == 1)  # Won\n",
    "n_neg = sum(y_train == 0)  # Lost\n",
    "scale_pos_weight = n_neg / n_pos\n",
    "\n",
    "model_xgb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocess_gb),  # same preprocessing as GB\n",
    "    ('model', XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        min_child_weight=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "model_xgb.fit(df_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = model_xgb.predict(df_val)\n",
    "y_proba_xgb = model_xgb.predict_proba(df_val)[:, 1]\n",
    "\n",
    "# Store results\n",
    "models_optimized['XGBoost'] = model_xgb\n",
    "results_optimized['XGBoost'] = {\n",
    "    'predictions': y_pred_xgb,\n",
    "    'probabilities': y_proba_xgb\n",
    "}\n",
    "\n",
    "print(\"✓ XGBoost trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce024f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Training LightGBM...\n",
      "--------------------------------------------------\n",
      "✓ LightGBM trained\n"
     ]
    }
   ],
   "source": [
    "# MODEL 2: LightGBM (often performs better on imbalanced data)\n",
    "print(\"\\n2. Training LightGBM...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "model_lgbm = Pipeline(steps=[\n",
    "    ('preprocessor', preprocess_gb), \n",
    "    ('model', LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=7,\n",
    "        num_leaves=31,\n",
    "        min_child_samples=30,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.7, \n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        verbose=-1))\n",
    "])\n",
    "\n",
    "model_lgbm.fit(df_train, y_train)\n",
    "\n",
    "y_pred_lgbm = model_lgbm.predict(df_val)\n",
    "y_proba_lgbm = model_lgbm.predict_proba(df_val)[:, 1]\n",
    "\n",
    "models_optimized['LightGBM'] = model_lgbm\n",
    "results_optimized['LightGBM'] = {\n",
    "    'predictions': y_pred_lgbm,\n",
    "    'probabilities': y_proba_lgbm\n",
    "}\n",
    "\n",
    "print(\"✓ LightGBM trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da64e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Training Optimized Gradient Boosting...\n",
      "--------------------------------------------------\n",
      "✓ Gradient Boosting trained\n"
     ]
    }
   ],
   "source": [
    "# MODEL 3: Optimized Gradient Boosting\n",
    "print(\"\\n3. Training Optimized Gradient Boosting...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "model_gb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocess_gb), \n",
    "    ('model', GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    subsample=0.8,\n",
    "    max_features='sqrt',\n",
    "    random_state=42))\n",
    "])\n",
    "\n",
    "model_gb.fit(df_train, y_train)\n",
    "\n",
    "y_pred_gb = model_gb.predict(df_val)\n",
    "y_proba_gb = model_gb.predict_proba(df_val)[:, 1]\n",
    "\n",
    "models_optimized['GradientBoosting'] = model_gb\n",
    "results_optimized['GradientBoosting'] = {\n",
    "    'predictions': y_pred_gb,\n",
    "    'probabilities': y_proba_gb\n",
    "}\n",
    "\n",
    "print(\"✓ Gradient Boosting trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f464c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Training Optimized Logistic Regression...\n",
      "--------------------------------------------------\n",
      "✓ Logistic Regression trained\n"
     ]
    }
   ],
   "source": [
    "# MODEL 4: Optimized Logistic Regression\n",
    "print(\"\\n4. Training Optimized Logistic Regression...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "lr_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocess_lr), \n",
    "    ('model', LogisticRegression(\n",
    "        C=0.1,\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        solver='saga',\n",
    "        penalty='elasticnet',\n",
    "        l1_ratio=0.5 ))\n",
    "    ])\n",
    "\n",
    "lr_model.fit(df_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(df_val)\n",
    "y_proba_lr = lr_model.predict_proba(df_val)[:, 1]\n",
    "\n",
    "models_optimized['LogisticRegression'] = lr_model\n",
    "results_optimized['LogisticRegression'] = {\n",
    "    'predictions': y_pred_lr,\n",
    "    'probabilities': y_proba_lr\n",
    "}\n",
    "\n",
    "print(\"✓ Logistic Regression trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e20d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL EVALUATION - OPTIMIZED MODELS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL EVALUATION - OPTIMIZED MODELS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f75490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.5641\n",
      "ROC-AUC:    0.5670  ← MAIN METRIC\n",
      "Precision:  0.6597\n",
      "Recall:     0.6355\n",
      "F1-Score:   0.6474\n",
      "\n",
      "LightGBM\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.5596\n",
      "ROC-AUC:    0.5627  ← MAIN METRIC\n",
      "Precision:  0.6508\n",
      "Recall:     0.6485\n",
      "F1-Score:   0.6497\n",
      "\n",
      "GradientBoosting\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.6073\n",
      "ROC-AUC:    0.5633  ← MAIN METRIC\n",
      "Precision:  0.6420\n",
      "Recall:     0.8509\n",
      "F1-Score:   0.7318\n",
      "\n",
      "LogisticRegression\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.6043\n",
      "ROC-AUC:    0.5433  ← MAIN METRIC\n",
      "Precision:  0.6340\n",
      "Recall:     0.8793\n",
      "F1-Score:   0.7367\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "\n",
    "for model_name, results in results_optimized.items():\n",
    "    y_pred = results['predictions']\n",
    "    y_proba = results['probabilities']\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_proba)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "    \n",
    "    evaluation_results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Accuracy:   {accuracy:.4f}\")\n",
    "    print(f\"ROC-AUC:    {roc_auc:.4f}  ← MAIN METRIC\")\n",
    "    print(f\"Precision:  {precision:.4f}\")\n",
    "    print(f\"Recall:     {recall:.4f}\")\n",
    "    print(f\"F1-Score:   {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "eval_comparison = pd.DataFrame(evaluation_results)\n",
    "eval_comparison = eval_comparison.sort_values('ROC-AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c206207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON (Sorted by ROC-AUC)\n",
      "================================================================================\n",
      "             Model  Accuracy  ROC-AUC  Precision   Recall  F1-Score\n",
      "           XGBoost  0.564083 0.567021   0.659705 0.635503  0.647378\n",
      "  GradientBoosting  0.607303 0.563321   0.641964 0.850888  0.731807\n",
      "          LightGBM  0.559613 0.562683   0.650831 0.648521  0.649674\n",
      "LogisticRegression  0.604322 0.543257   0.633959 0.879290  0.736738\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON (Sorted by ROC-AUC)\")\n",
    "print(\"=\"*80)\n",
    "print(eval_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0c7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CROSS-VALIDATION EVALUATION (5-Fold Stratified)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-VALIDATION EVALUATION (5-Fold Stratified)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f55173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full training set: 5368 samples\n",
      "Test set: 1343 samples\n"
     ]
    }
   ],
   "source": [
    "# Combine train + val for full training\n",
    "df_full_train = pd.concat([df_train, df_val], axis=0).reset_index(drop=True)\n",
    "y_full_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "print(f\"\\nFull training set: {len(df_full_train)} samples\")\n",
    "print(f\"Test set: {len(df_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3759c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stratified k-fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Models to evaluate\n",
    "cv_models = {\n",
    "    'XGBoost': model_xgb,\n",
    "    'LightGBM': model_lgbm,\n",
    "    'GradientBoosting': model_gb,\n",
    "    'LogisticRegression': lr_model\n",
    "}\n",
    "\n",
    "cv_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e97d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running 5-Fold Cross-Validation...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Evaluating XGBoost...\n",
      "  ROC-AUC: 0.5975 (±0.0119)\n",
      "  Accuracy: 0.5833\n",
      "  F1-Score: 0.6546\n",
      "\n",
      "Evaluating LightGBM...\n",
      "  ROC-AUC: 0.5913 (±0.0112)\n",
      "  Accuracy: 0.5849\n",
      "  F1-Score: 0.6624\n",
      "\n",
      "Evaluating GradientBoosting...\n",
      "  ROC-AUC: 0.5949 (±0.0047)\n",
      "  Accuracy: 0.6257\n",
      "  F1-Score: 0.7411\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "  ROC-AUC: 0.5911 (±0.0149)\n",
      "  Accuracy: 0.6354\n",
      "  F1-Score: 0.7627\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRunning 5-Fold Cross-Validation...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for model_name, model in cv_models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    fold_scores = {\n",
    "        'roc_auc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': []\n",
    "    }\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df_full_train, y_full_train), 1):\n",
    "        # Split data\n",
    "        X_train_fold = df_full_train.iloc[train_idx]\n",
    "        X_val_fold = df_full_train.iloc[val_idx]\n",
    "        y_train_fold = y_full_train[train_idx]\n",
    "        y_val_fold = y_full_train[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        y_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "        \n",
    "        # Metrics\n",
    "        fold_scores['roc_auc'].append(roc_auc_score(y_val_fold, y_proba))\n",
    "        fold_scores['accuracy'].append(accuracy_score(y_val_fold, y_pred))\n",
    "        fold_scores['precision'].append(precision_score(y_val_fold, y_pred, zero_division=0))\n",
    "        fold_scores['recall'].append(recall_score(y_val_fold, y_pred, zero_division=0))\n",
    "        fold_scores['f1'].append(f1_score(y_val_fold, y_pred, zero_division=0))\n",
    "    \n",
    "    # Store results\n",
    "    cv_results[model_name] = {\n",
    "        'roc_auc_mean': np.mean(fold_scores['roc_auc']),\n",
    "        'roc_auc_std': np.std(fold_scores['roc_auc']),\n",
    "        'accuracy_mean': np.mean(fold_scores['accuracy']),\n",
    "        'precision_mean': np.mean(fold_scores['precision']),\n",
    "        'recall_mean': np.mean(fold_scores['recall']),\n",
    "        'f1_mean': np.mean(fold_scores['f1'])\n",
    "    }\n",
    "    \n",
    "    print(f\"  ROC-AUC: {cv_results[model_name]['roc_auc_mean']:.4f} (±{cv_results[model_name]['roc_auc_std']:.4f})\")\n",
    "    print(f\"  Accuracy: {cv_results[model_name]['accuracy_mean']:.4f}\")\n",
    "    print(f\"  F1-Score: {cv_results[model_name]['f1_mean']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075758ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CROSS-VALIDATION RESULTS (Sorted by ROC-AUC)\n",
      "================================================================================\n",
      "                    roc_auc_mean  roc_auc_std  accuracy_mean   f1_mean\n",
      "XGBoost                 0.597455     0.011887       0.583270  0.654608\n",
      "GradientBoosting        0.594930     0.004703       0.625742  0.741080\n",
      "LightGBM                0.591256     0.011161       0.584949  0.662399\n",
      "LogisticRegression      0.591137     0.014914       0.635434  0.762749\n"
     ]
    }
   ],
   "source": [
    "# Create CV results dataframe\n",
    "cv_df = pd.DataFrame(cv_results).T\n",
    "cv_df = cv_df.sort_values('roc_auc_mean', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-VALIDATION RESULTS (Sorted by ROC-AUC)\")\n",
    "print(\"=\"*80)\n",
    "print(cv_df[['roc_auc_mean', 'roc_auc_std', 'accuracy_mean', 'f1_mean']].to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5c51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "HYPERPARAMETER TUNING (Best Model: XGBoost)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPERPARAMETER TUNING (Best Model: XGBoost)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a2173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class balance: Lost=2001, Won=3367\n",
      "Scale pos weight: 0.59\n"
     ]
    }
   ],
   "source": [
    "# Calculate scale_pos_weight for imbalanced data\n",
    "n_neg = sum(y_full_train == 0)  # lost\n",
    "n_pos = sum(y_full_train == 1)  # won\n",
    "scale_pos_weight = n_neg / n_pos\n",
    "\n",
    "print(f\"\\nClass balance: Lost={n_neg}, Won={n_pos}\")\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f041808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for best hyperparameters...\n",
      "(This may take 5-10 minutes)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost hyperparameter grid\n",
    "param_distributions = {\n",
    "    'model__n_estimators': [200, 300, 500],\n",
    "    'model__max_depth': [4, 5, 6, 7],\n",
    "    'model__learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'model__min_child_weight': [3, 5, 7],\n",
    "    'model__subsample': [0.7, 0.8, 0.9],\n",
    "    'model__colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'model__gamma': [0, 0.1, 0.2],\n",
    "    'model__reg_alpha': [0, 0.5, 1],\n",
    "    'model__reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "print(\"\\nSearching for best hyperparameters...\")\n",
    "print(\"(This may take 5-10 minutes)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc072c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "\n",
      "✓ Hyperparameter tuning complete!\n",
      "\n",
      "Best ROC-AUC (CV): 0.6162\n",
      "\n",
      "Best Hyperparameters:\n",
      "  model__subsample: 0.9\n",
      "  model__reg_lambda: 1\n",
      "  model__reg_alpha: 0\n",
      "  model__n_estimators: 200\n",
      "  model__min_child_weight: 3\n",
      "  model__max_depth: 4\n",
      "  model__learning_rate: 0.01\n",
      "  model__gamma: 0.1\n",
      "  model__colsample_bytree: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Recreate preprocessing\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cb', CatBoostEncoder(cols=categorical), categorical),\n",
    "        ('num_reg_pass', 'passthrough', numerical_eng)  # explicitly pass numerical_reg only\n",
    "    ],\n",
    "    remainder='drop'  # drop all other columns (like original numerical)\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocess),\n",
    "    ('model', XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb_pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,  # Try 30 random combinations\n",
    "    scoring='roc_auc',\n",
    "    cv=3,  # 3-fold CV for speed\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(df_full_train, y_full_train)\n",
    "\n",
    "print(\"\\n✓ Hyperparameter tuning complete!\")\n",
    "print(f\"\\nBest ROC-AUC (CV): {random_search.best_score_:.4f}\")\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Store best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5405f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (5368, 36)\n",
      "  Won (1): 3367\n",
      "  Lost (0): 2001\n"
     ]
    }
   ],
   "source": [
    "# Preprocess full training data\n",
    "X_full_train_processed = preprocess.fit_transform(df_full_train, y_full_train)\n",
    "\n",
    "print(f\"  Shape: {X_full_train_processed.shape}\")\n",
    "print(f\"  Won (1): {sum(y_full_train == 1)}\")\n",
    "print(f\"  Lost (0): {sum(y_full_train == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fadc24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final model...\n",
      "✓ Final model trained!\n"
     ]
    }
   ],
   "source": [
    "# Train final model with best hyperparameters on SMOTE data\n",
    "final_model = XGBClassifier(\n",
    "    **{k.replace('model__', ''): v for k, v in random_search.best_params_.items()},\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTraining final model...\")\n",
    "final_model.fit(X_full_train_processed, y_full_train)\n",
    "print(\"✓ Final model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1445bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL EVALUATION ON TEST SET\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test data\n",
    "X_test_processed = preprocess.transform(df_test)\n",
    "\n",
    "# Predictions\n",
    "y_test_pred = final_model.predict(X_test_processed)\n",
    "y_test_proba = final_model.predict_proba(X_test_processed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "test_precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "test_recall = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "test_f1 = f1_score(y_test, y_test_pred, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e1146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 FINAL TEST SET RESULTS:\n",
      "================================================================================\n",
      "Accuracy:    0.5838\n",
      "ROC-AUC:     0.5974  ← PRIMARY METRIC\n",
      "Precision:   0.7037  (Of predicted WIN, how many correct?)\n",
      "Recall:      0.6188  (Of actual WIN, how many caught?)\n",
      "F1-Score:    0.6585\n",
      "\n",
      "📊 Classification Report:\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Won (1)       0.42      0.52      0.47       472\n",
      "    Lost (0)       0.70      0.62      0.66       871\n",
      "\n",
      "    accuracy                           0.58      1343\n",
      "   macro avg       0.56      0.57      0.56      1343\n",
      "weighted avg       0.61      0.58      0.59      1343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🎯 FINAL TEST SET RESULTS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy:    {test_accuracy:.4f}\")\n",
    "print(f\"ROC-AUC:     {test_roc_auc:.4f}  ← PRIMARY METRIC\")\n",
    "print(f\"Precision:   {test_precision:.4f}  (Of predicted WIN, how many correct?)\")\n",
    "print(f\"Recall:      {test_recall:.4f}  (Of actual WIN, how many caught?)\")\n",
    "print(f\"F1-Score:    {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\n📊 Classification Report:\")\n",
    "print(\"-\" * 80)\n",
    "print(classification_report(y_test, y_test_pred, \n",
    "                          target_names=['Won (1)', 'Lost (0)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e0862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Confusion Matrix:\n",
      "--------------------------------------------------------------------------------\n",
      "                Predicted Won    Predicted Lost\n",
      "Actual Lost               245               227\n",
      "Actual Won              332               539\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"\\n📈 Confusion Matrix:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"                Predicted Won    Predicted Lost\")\n",
    "print(f\"Actual Lost      {cm[0,0]:>12}    {cm[0,1]:>14}\")\n",
    "print(f\"Actual Won     {cm[1,0]:>12}    {cm[1,1]:>14}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbb268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c50047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Top 20 Most Important Features:\n",
      "--------------------------------------------------------------------------------\n",
      "                  feature  importance\n",
      "                 deal_age    0.092213\n",
      "velocity_complexity_index    0.046506\n",
      "           days_into_year    0.042592\n",
      "     sales_velocity_ratio    0.041078\n",
      "           is_quarter_end    0.039824\n",
      "pace_weighted_agent_score    0.037503\n",
      "         account_win_rate    0.036631\n",
      "                  account    0.032977\n",
      "    agent_product_synergy    0.032800\n",
      "            month_engaged    0.030187\n",
      "          office_win_rate    0.029319\n",
      "          office_location    0.027421\n",
      "          region_win_rate    0.026709\n",
      "          regional_office    0.026680\n",
      "                  manager    0.025290\n",
      "          deal_complexity    0.025010\n",
      "         product_win_rate    0.024915\n",
      "                   sector    0.024196\n",
      "          agent_vs_sector    0.023739\n",
      "             quarter_risk    0.023547\n"
     ]
    }
   ],
   "source": [
    "# Get feature names after preprocessing\n",
    "feature_names = (\n",
    "    categorical + \n",
    "    numerical_eng\n",
    ")\n",
    "\n",
    "# Get feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names[:len(final_model.feature_importances_)],\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n📊 Top 20 Most Important Features:\")\n",
    "print(\"-\" * 80)\n",
    "print(importance_df.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dcf134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8e4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "             Model  CV ROC-AUC Test ROC-AUC\n",
      "   XGBoost (Tuned)    0.616198     0.597385\n",
      "XGBoost (Original)    0.597455            -\n",
      "          LightGBM    0.591256            -\n",
      "  GradientBoosting    0.594930            -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "comparison_summary = pd.DataFrame({\n",
    "    'Model': ['XGBoost (Tuned)', 'XGBoost (Original)', 'LightGBM', 'GradientBoosting'],\n",
    "    'CV ROC-AUC': [\n",
    "        random_search.best_score_,\n",
    "        cv_results['XGBoost']['roc_auc_mean'],\n",
    "        cv_results['LightGBM']['roc_auc_mean'],\n",
    "        cv_results['GradientBoosting']['roc_auc_mean']\n",
    "    ],\n",
    "    'Test ROC-AUC': [\n",
    "        test_roc_auc,\n",
    "        '-',\n",
    "        '-',\n",
    "        '-'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\")\n",
    "print(comparison_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac320c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "THRESHOLD OPTIMIZATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"THRESHOLD OPTIMIZATION\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d49bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal threshold: 0.327\n",
      "At this threshold:\n",
      "  Precision: 0.6536\n",
      "  Recall: 0.9989\n",
      "  F1-Score: 0.7902\n"
     ]
    }
   ],
   "source": [
    "# Get precision-recall curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_test_proba)\n",
    "\n",
    "# Find optimal threshold (maximize F1)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx] if optimal_idx < len(thresholds) else 0.5\n",
    "\n",
    "print(f\"\\nOptimal threshold: {optimal_threshold:.3f}\")\n",
    "print(f\"At this threshold:\")\n",
    "print(f\"  Precision: {precisions[optimal_idx]:.4f}\")\n",
    "print(f\"  Recall: {recalls[optimal_idx]:.4f}\")\n",
    "print(f\"  F1-Score: {f1_scores[optimal_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f29095c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With optimal threshold:\n",
      "  Accuracy: 0.6560\n",
      "  F1-Score: 0.7902\n"
     ]
    }
   ],
   "source": [
    "# Apply optimal threshold\n",
    "y_test_pred_optimal = (y_test_proba >= optimal_threshold).astype(int)\n",
    "optimal_accuracy = accuracy_score(y_test, y_test_pred_optimal)\n",
    "optimal_f1 = f1_score(y_test, y_test_pred_optimal)\n",
    "\n",
    "print(f\"\\nWith optimal threshold:\")\n",
    "print(f\"  Accuracy: {optimal_accuracy:.4f}\")\n",
    "print(f\"  F1-Score: {optimal_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee6b68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAVING FINAL MODEL\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING FINAL MODEL\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149720b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Model saved as 'sales_pipeline_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model and preprocessing pipeline\n",
    "model_artifacts = {\n",
    "    'model': final_model,\n",
    "    'preprocessor': preprocess,\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "    'feature_names': feature_names,\n",
    "    'categorical_features': categorical,\n",
    "    'numerical_features': numerical,\n",
    "    'test_roc_auc': test_roc_auc,\n",
    "    'best_params': random_search.best_params_\n",
    "}\n",
    "\n",
    "with open('sales_pipeline_model.pkl', 'wb') as f_out:\n",
    "    pickle.dump(model_artifacts, f_out)\n",
    "\n",
    "print(\"\\n✓ Model saved as 'sales_pipeline_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffd2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "10. PRODUCTION PREDICTION FUNCTION\n",
      "================================================================================\n",
      "\n",
      "✓ Production prediction function ready!\n",
      "\n",
      "Usage example:\n",
      "  predictions = predict_deal_outcome(df_active, model_artifacts)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"10. PRODUCTION PREDICTION FUNCTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def predict_deal_outcome(df_new, model_artifacts, use_optimal_threshold=True):\n",
    "    \"\"\"\n",
    "    Predict outcomes for new deals\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_new : DataFrame\n",
    "        New deals to predict (must have same features as training data)\n",
    "    model_artifacts : dict\n",
    "        Saved model artifacts\n",
    "    use_optimal_threshold : bool\n",
    "        Whether to use optimal threshold (default: True)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with predictions and probabilities\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    X_new = model_artifacts['preprocessor'].transform(df_new)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    proba = model_artifacts['model'].predict_proba(X_new)[:, 1]\n",
    "    \n",
    "    # Apply threshold\n",
    "    threshold = model_artifacts['optimal_threshold'] if use_optimal_threshold else 0.5\n",
    "    predictions = (proba >= threshold).astype(int)\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results = pd.DataFrame({\n",
    "        'predicted_outcome': ['Lost' if p == 0 else 'Won' for p in predictions],\n",
    "        'probability_won': proba,\n",
    "        'probability_lost': 1 - proba,\n",
    "        'confidence': np.maximum(proba, 1 - proba)\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"\\n✓ Production prediction function ready!\")\n",
    "print(\"\\nUsage example:\")\n",
    "print(\"  predictions = predict_deal_outcome(df_active, model_artifacts)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab0372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_outcome</th>\n",
       "      <th>probability_won</th>\n",
       "      <th>probability_lost</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Won</td>\n",
       "      <td>0.724013</td>\n",
       "      <td>0.275987</td>\n",
       "      <td>0.724013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Won</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.679100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Won</td>\n",
       "      <td>0.733199</td>\n",
       "      <td>0.266801</td>\n",
       "      <td>0.733199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Won</td>\n",
       "      <td>0.712602</td>\n",
       "      <td>0.287398</td>\n",
       "      <td>0.712602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Won</td>\n",
       "      <td>0.764013</td>\n",
       "      <td>0.235987</td>\n",
       "      <td>0.764013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>Won</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.271523</td>\n",
       "      <td>0.728477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>Won</td>\n",
       "      <td>0.631590</td>\n",
       "      <td>0.368410</td>\n",
       "      <td>0.631590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>Won</td>\n",
       "      <td>0.729477</td>\n",
       "      <td>0.270523</td>\n",
       "      <td>0.729477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>Won</td>\n",
       "      <td>0.705855</td>\n",
       "      <td>0.294145</td>\n",
       "      <td>0.705855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>Won</td>\n",
       "      <td>0.740283</td>\n",
       "      <td>0.259717</td>\n",
       "      <td>0.740283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1589 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted_outcome  probability_won  probability_lost  confidence\n",
       "0                  Won         0.724013          0.275987    0.724013\n",
       "1                  Won         0.679100          0.320900    0.679100\n",
       "2                  Won         0.733199          0.266801    0.733199\n",
       "3                  Won         0.712602          0.287398    0.712602\n",
       "4                  Won         0.764013          0.235987    0.764013\n",
       "...                ...              ...               ...         ...\n",
       "1584               Won         0.728477          0.271523    0.728477\n",
       "1585               Won         0.631590          0.368410    0.631590\n",
       "1586               Won         0.729477          0.270523    0.729477\n",
       "1587               Won         0.705855          0.294145    0.705855\n",
       "1588               Won         0.740283          0.259717    0.740283\n",
       "\n",
       "[1589 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict_deal_outcome(df_active, model_artifacts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🎉 PROJECT COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 PROJECT COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d58ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All Steps Completed Successfully:\n",
      "\n",
      "1. ✓ Fixed target variable encoding (Lost=0, Won=1)\n",
      "2. ✓ Performed 5-fold cross-validation\n",
      "3. ✓ Tuned hyperparameters (30 iterations)\n",
      "4. ✓ Trained final model on full training data\n",
      "5. ✓ Evaluated on held-out test set\n",
      "6. ✓ Analyzed feature importance\n",
      "7. ✓ Optimized prediction threshold\n",
      "8. ✓ Saved production-ready model\n",
      "9. ✓ Created prediction function\n",
      "\n",
      "📊 FINAL RESULTS:\n",
      "   - Test ROC-AUC: 0.5974\n",
      "   - Test Accuracy: 0.5838\n",
      "   - Test F1-Score: 0.6585\n",
      "   \n",
      "🎯 Model Improvement: 2.0 percentage points\n",
      "   (From original 0.577 to 0.5974)\n",
      "\n",
      "📦 Model saved as: sales_pipeline_model.pkl\n",
      "\n",
      "🚀 Next Steps:\n",
      "   - Monitor model performance on new data\n",
      "   - Retrain monthly with new deals\n",
      "   - Consider A/B testing in production\n",
      "   - Set up alerts for prediction confidence < 60%\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "✅ All Steps Completed Successfully:\n",
    "\n",
    "1. ✓ Fixed target variable encoding (Lost=0, Won=1)\n",
    "2. ✓ Performed 5-fold cross-validation\n",
    "3. ✓ Tuned hyperparameters (30 iterations)\n",
    "4. ✓ Trained final model on full training data\n",
    "5. ✓ Evaluated on held-out test set\n",
    "6. ✓ Analyzed feature importance\n",
    "7. ✓ Optimized prediction threshold\n",
    "8. ✓ Saved production-ready model\n",
    "9. ✓ Created prediction function\n",
    "\n",
    "📊 FINAL RESULTS:\n",
    "   - Test ROC-AUC: {test_roc_auc:.4f}\n",
    "   - Test Accuracy: {test_accuracy:.4f}\n",
    "   - Test F1-Score: {test_f1:.4f}\n",
    "   \n",
    "🎯 Model Improvement: {(test_roc_auc - 0.577)*100:.1f} percentage points\n",
    "   (From original 0.577 to {test_roc_auc:.4f})\n",
    "\n",
    "📦 Model saved as: sales_pipeline_model.pkl\n",
    "\n",
    "🚀 Next Steps:\n",
    "   - Monitor model performance on new data\n",
    "   - Retrain monthly with new deals\n",
    "   - Consider A/B testing in production\n",
    "   - Set up alerts for prediction confidence < 60%\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
